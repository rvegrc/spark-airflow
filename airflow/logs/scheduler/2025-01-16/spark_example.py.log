[2025-01-16T19:21:41.984+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:21:41.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:21:42.027+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:42.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:21:42.351+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:21:42.522+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:42.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:21:42.828+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:42.827+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:21:43.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 1.509 seconds
[2025-01-16T19:22:13.681+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:13.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:22:13.694+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:13.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:13.761+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:13.874+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:13.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:22:13.934+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:13.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:22:14.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.393 seconds
[2025-01-16T19:22:44.711+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:44.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:22:44.722+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:44.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:44.783+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:22:44.860+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:44.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:22:44.906+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:44.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:22:44.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.282 seconds
[2025-01-16T19:23:15.568+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:15.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:23:15.580+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:15.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:15.635+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:15.707+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:15.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:23:15.756+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:15.756+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:23:15.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.277 seconds
[2025-01-16T19:23:45.988+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:45.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:23:46.002+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:46.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:46.064+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:23:46.149+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:46.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:23:46.203+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:46.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:23:46.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.310 seconds
[2025-01-16T19:24:16.761+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:16.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:24:16.772+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:16.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:17.199+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:17.389+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:17.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:24:17.525+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:17.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:24:17.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.947 seconds
[2025-01-16T19:24:48.087+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:48.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:24:48.091+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:48.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:48.117+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:24:48.153+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:48.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:24:48.172+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:48.172+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:24:48.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.134 seconds
[2025-01-16T19:25:18.585+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:18.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:25:18.599+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:18.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:18.736+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:18.850+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:18.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:25:18.914+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:18.913+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:25:18.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.429 seconds
[2025-01-16T19:25:49.573+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:49.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:25:49.587+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:49.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:49.651+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:25:49.743+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:49.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:25:49.797+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:49.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:25:50.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.679 seconds
[2025-01-16T19:26:20.575+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:20.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:26:20.598+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:20.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:20.779+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:20.899+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:20.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:26:21.345+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:21.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:26:21.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.931 seconds
[2025-01-16T19:26:52.252+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:52.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:26:52.280+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:52.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:52.503+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:26:52.607+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:52.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:26:52.668+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:52.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:26:52.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.530 seconds
[2025-01-16T19:27:22.961+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:22.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:27:22.967+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:22.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:23.005+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:23.048+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:23.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:27:23.075+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:23.075+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:27:23.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.172 seconds
[2025-01-16T19:27:53.533+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:53.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:27:53.539+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:53.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:53.571+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:27:53.608+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:53.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:27:53.628+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:53.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:27:53.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.134 seconds
[2025-01-16T19:28:23.948+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:23.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:28:23.954+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:23.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:23.975+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:24.005+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:24.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:28:24.021+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:24.020+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:28:24.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.266 seconds
[2025-01-16T19:28:54.838+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:54.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:28:54.843+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:54.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:54.866+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:28:54.903+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:54.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:28:55.140+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:55.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T19:28:55.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.349 seconds
[2025-01-16T19:29:25.715+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:25.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:29:25.718+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:29:25.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:25.738+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:26.826+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-16T19:29:56.978+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:56.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T19:29:56.982+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:29:56.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:57.000+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T19:29:58.045+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-16T20:05:46.582+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:05:46.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:05:46.589+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:46.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:05:46.624+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:05:47.121+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:47.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:05:47.143+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:47.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:05:47.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.612 seconds
[2025-01-16T20:06:17.683+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:17.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:06:17.687+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:17.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:17.698+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:17.715+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:17.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:06:17.725+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:17.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:06:17.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.077 seconds
[2025-01-16T20:06:48.030+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:48.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:06:48.033+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:48.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:48.053+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:06:48.079+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:48.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:06:48.090+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:48.089+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:06:48.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.106 seconds
[2025-01-16T20:07:18.289+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:18.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:07:18.293+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:18.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:18.314+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:18.335+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:18.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:07:18.346+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:18.345+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:07:18.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.084 seconds
[2025-01-16T20:07:48.656+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:48.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:07:48.658+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:48.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:48.669+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:07:48.686+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:48.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:07:48.696+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:48.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:07:48.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.173 seconds
[2025-01-16T20:08:18.890+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:18.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:08:18.894+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:18.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:18.908+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:18.929+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:18.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:08:19.082+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:19.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:08:19.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.227 seconds
[2025-01-16T20:08:49.687+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:49.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:08:49.690+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:49.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:49.703+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:08:49.850+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:49.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:08:49.861+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:49.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:08:49.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.208 seconds
[2025-01-16T20:09:20.679+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:20.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:09:20.682+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:20.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:20.703+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:20.723+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:20.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:09:20.735+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:20.735+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:09:20.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.106 seconds
[2025-01-16T20:09:50.906+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:50.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:09:50.908+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:50.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:50.917+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:09:50.934+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:50.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:09:50.947+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:50.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:09:50.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.075 seconds
[2025-01-16T20:10:21.106+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:21.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:10:21.110+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:21.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:21.131+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:21.150+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:21.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:10:21.161+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:21.161+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:10:21.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.082 seconds
[2025-01-16T20:10:52.070+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:52.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:10:52.074+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:52.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:52.091+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:10:52.116+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:52.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:10:52.129+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:52.129+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:10:52.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.086 seconds
[2025-01-16T20:11:22.881+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:22.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:11:22.884+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:22.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:22.896+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:22.913+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:22.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:11:22.923+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:22.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:11:22.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.080 seconds
[2025-01-16T20:11:53.246+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:53.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:11:53.248+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:53.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:53.262+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:11:53.280+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:53.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:11:53.291+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:53.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:11:53.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.086 seconds
[2025-01-16T20:12:24.015+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:24.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:12:24.018+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:24.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:24.034+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:24.062+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:24.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:12:24.074+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:24.073+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:12:24.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.086 seconds
[2025-01-16T20:12:54.241+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:54.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:12:54.244+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:54.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:54.256+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:12:54.278+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:54.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:12:54.288+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:54.288+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:12:54.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.070 seconds
[2025-01-16T20:13:24.846+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:24.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:13:24.850+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:24.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:24.874+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:24.892+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:24.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:13:24.902+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:24.902+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:13:24.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.083 seconds
[2025-01-16T20:13:55.600+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:55.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:13:55.603+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:55.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:55.612+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:13:55.629+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:55.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:13:55.639+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:55.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:13:55.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.061 seconds
[2025-01-16T20:14:26.253+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:26.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:14:26.266+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:26.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:26.326+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:26.347+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:26.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:14:26.357+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:26.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:14:26.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.130 seconds
[2025-01-16T20:14:57.211+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:57.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:14:57.215+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:57.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:57.239+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:14:57.262+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:57.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:14:57.272+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:57.272+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:14:57.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.099 seconds
[2025-01-16T20:15:27.875+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:27.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:15:27.877+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:27.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:27.888+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:27.905+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:27.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:15:27.915+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:27.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:15:27.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.066 seconds
[2025-01-16T20:15:58.004+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:58.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:15:58.007+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:58.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:58.019+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:15:58.037+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:58.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:15:58.047+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:58.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:15:58.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.067 seconds
[2025-01-16T20:16:28.808+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:28.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:16:28.812+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:28.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:28.892+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:28.913+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:28.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:16:28.923+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:28.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:16:28.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.141 seconds
[2025-01-16T20:16:59.085+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:59.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:16:59.088+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:59.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:59.101+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:16:59.120+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:59.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:16:59.130+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:59.130+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:16:59.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.068 seconds
[2025-01-16T20:17:29.525+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:29.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:17:29.528+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:29.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:29.537+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:29.557+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:29.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:17:29.601+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:29.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:17:29.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.098 seconds
[2025-01-16T20:17:59.673+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:59.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:17:59.675+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:59.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:59.684+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:17:59.700+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:59.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:17:59.711+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:59.711+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:17:59.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.062 seconds
[2025-01-16T20:18:29.841+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:18:29.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:18:29.845+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:29.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:18:29.862+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:18:29.885+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:29.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:18:29.899+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:29.899+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:18:29.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.098 seconds
[2025-01-16T20:19:00.337+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:00.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:19:00.341+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:00.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:00.358+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:00.385+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:00.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:19:00.399+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:00.398+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:19:00.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.101 seconds
[2025-01-16T20:19:30.791+0000] {processor.py:186} INFO - Started process (PID=375) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:30.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:19:30.796+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:30.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:30.812+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:19:30.837+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:30.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:19:30.851+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:30.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:19:30.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.104 seconds
[2025-01-16T20:20:01.040+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:01.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:20:01.043+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:01.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:01.064+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:01.084+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:01.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:20:01.100+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:01.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:20:01.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.101 seconds
[2025-01-16T20:20:31.237+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:31.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:20:31.240+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:31.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:31.257+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:20:31.282+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:31.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:20:31.297+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:31.296+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:20:31.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.097 seconds
[2025-01-16T20:21:01.637+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:01.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:21:01.642+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:01.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:01.680+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:01.705+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:01.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:21:01.720+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:01.720+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:21:01.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.116 seconds
[2025-01-16T20:21:32.296+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:32.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:21:32.300+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:32.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:32.325+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:21:32.345+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:32.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:21:32.357+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:32.357+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:21:32.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.094 seconds
[2025-01-16T20:22:02.567+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:02.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:22:02.571+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:02.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:02.598+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:02.623+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:02.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:22:02.635+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:02.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:22:02.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.100 seconds
[2025-01-16T20:22:32.738+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:32.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:22:32.742+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:32.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:32.758+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:22:32.782+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:32.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:22:32.808+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:32.808+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:22:32.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.119 seconds
[2025-01-16T20:23:03.239+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:03.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:23:03.243+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:03.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:03.264+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:03.288+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:03.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:23:03.302+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:03.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:23:03.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.107 seconds
[2025-01-16T20:23:33.564+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:33.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:23:33.568+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:33.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:33.590+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:23:33.615+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:33.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:23:33.628+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:33.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:23:33.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.108 seconds
[2025-01-16T20:24:03.763+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:03.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:24:03.766+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:03.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:03.778+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:03.795+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:03.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:24:03.804+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:03.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:24:03.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.077 seconds
[2025-01-16T20:24:33.945+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:33.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:24:33.950+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:33.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:33.972+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:24:33.997+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:33.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:24:34.012+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:34.012+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:24:34.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.103 seconds
[2025-01-16T20:25:04.237+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:04.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:25:04.240+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:04.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:04.252+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:04.274+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:04.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:25:04.287+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:04.287+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:25:04.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.077 seconds
[2025-01-16T20:25:35.019+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:35.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:25:35.022+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:35.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:35.036+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:25:35.060+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:35.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:25:35.073+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:35.073+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:25:35.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.096 seconds
[2025-01-16T20:26:05.218+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:05.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:26:05.227+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:05.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:05.249+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:05.267+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:05.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:26:05.278+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:05.278+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:26:05.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.095 seconds
[2025-01-16T20:26:35.852+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:35.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_example.py for tasks to queue
[2025-01-16T20:26:35.854+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:35.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:35.865+0000] {processor.py:925} INFO - DAG(s) 'spark_example' retrieved from /opt/airflow/dags/spark_example.py
[2025-01-16T20:26:35.883+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:35.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:26:35.894+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:35.893+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_example to None, run_after=None
[2025-01-16T20:26:35.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_example.py took 0.083 seconds
