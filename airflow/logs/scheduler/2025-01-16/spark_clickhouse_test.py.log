[2025-01-16T19:21:05.543+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:05.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:21:05.643+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:05.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:42.049+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:42.043+0000] {timeout.py:68} ERROR - Process timed out, PID: 92
[2025-01-16T19:21:42.284+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:42.091+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_clickhouse_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_clickhouse_test.py", line 9, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 23, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/__init__.py", line 285, in <module>
    from pyarrow.ipc import serialize_pandas, deserialize_pandas
  File "<frozen importlib._bootstrap>", line 1354, in _find_and_load
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_clickhouse_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 92
[2025-01-16T19:21:42.298+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:43.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 38.178 seconds
[2025-01-16T19:21:44.131+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:44.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:21:44.140+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:44.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:56.231+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:21:56.307+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.305+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'spark_clickhouse_test', 'Task Id': 'run', 'Run Id': 'manual__2025-01-14T19:26:48.830405+00:00', 'Hostname': 'd7079d55ba46', 'External Executor Id': 'cd1aa729-e0f9-4451-abe7-b836de1365d1'}
[2025-01-16T19:21:56.404+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.403+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=spark_clickhouse_test, task_id=run, run_id=manual__2025-01-14T19:26:48.830405+00:00, execution_date=20250114T192648, start_date=20250114T192712, end_date=20250116T192156
[2025-01-16T19:21:56.492+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.491+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: spark_clickhouse_test.run manual__2025-01-14T19:26:48.830405+00:00 [failed]> in state failed
[2025-01-16T19:21:56.509+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.508+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'spark_clickhouse_test', 'Task Id': 'run', 'Run Id': 'manual__2025-01-14T19:26:48.830405+00:00', 'Hostname': 'd7079d55ba46', 'External Executor Id': 'cd1aa729-e0f9-4451-abe7-b836de1365d1'}
[2025-01-16T19:21:56.548+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.547+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=spark_clickhouse_test, task_id=run, run_id=manual__2025-01-14T19:26:48.830405+00:00, execution_date=20250114T192648, start_date=20250114T192712, end_date=20250116T192156
[2025-01-16T19:21:56.586+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.585+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: spark_clickhouse_test.run manual__2025-01-14T19:26:48.830405+00:00 [failed]> in state failed
[2025-01-16T19:21:56.917+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:56.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:21:57.015+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:21:57.013+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:21:57.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 12.835 seconds
[2025-01-16T19:22:28.172+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:22:28.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:22:28.202+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:28.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:22:33.450+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:22:33.502+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:33.500+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'spark_clickhouse_test', 'Task Id': 'run', 'Run Id': 'manual__2025-01-14T19:26:48.830405+00:00', 'Hostname': 'd7079d55ba46', 'External Executor Id': 'cd1aa729-e0f9-4451-abe7-b836de1365d1'}
[2025-01-16T19:22:33.572+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:33.571+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=spark_clickhouse_test, task_id=run, run_id=manual__2025-01-14T19:26:48.830405+00:00, execution_date=20250114T192648, start_date=20250114T192712, end_date=20250116T192233
[2025-01-16T19:22:33.615+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:33.614+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: spark_clickhouse_test.run manual__2025-01-14T19:26:48.830405+00:00 [failed]> in state failed
[2025-01-16T19:22:33.662+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:33.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:22:33.702+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:22:33.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:22:33.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 5.835 seconds
[2025-01-16T19:23:05.131+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:05.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:23:05.161+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:05.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:09.768+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:10.237+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:10.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:23:10.415+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:10.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:23:10.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 5.416 seconds
[2025-01-16T19:23:40.741+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:40.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:23:40.754+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:40.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:42.598+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:23:42.658+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:42.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:23:42.689+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:23:42.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:23:42.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 2.020 seconds
[2025-01-16T19:24:13.334+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:13.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:24:13.358+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:13.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:15.731+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:16.414+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:16.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:24:16.506+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:16.506+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:24:16.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 3.319 seconds
[2025-01-16T19:24:47.106+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:47.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:24:47.109+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:47.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:47.853+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:24:47.900+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:47.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:24:47.930+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:24:47.929+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:24:47.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.882 seconds
[2025-01-16T19:25:18.566+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:18.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:25:18.590+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:18.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:21.068+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:21.141+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:21.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:25:21.185+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:21.184+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:25:21.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 2.879 seconds
[2025-01-16T19:25:52.066+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:52.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:25:52.098+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:52.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:54.981+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:25:55.071+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:55.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:25:55.113+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:25:55.112+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:25:55.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 3.141 seconds
[2025-01-16T19:26:25.855+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:26:25.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:26:25.873+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:25.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:26:29.404+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:26:29.499+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:29.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:26:29.549+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:26:29.548+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:26:29.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 3.804 seconds
[2025-01-16T19:27:00.115+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:00.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:27:00.127+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:00.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:02.508+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:02.579+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:02.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:27:02.634+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:02.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:27:02.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 2.612 seconds
[2025-01-16T19:27:33.141+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:33.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:27:33.148+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:33.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:34.308+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:27:34.348+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:34.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:27:34.374+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:27:34.373+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:27:34.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 1.284 seconds
[2025-01-16T19:28:04.978+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:04.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:28:04.982+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:04.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:05.881+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:05.914+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:05.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:28:05.933+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:05.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:28:05.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.994 seconds
[2025-01-16T19:28:36.067+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:36.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:28:36.072+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:36.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:36.906+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:28:36.943+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:36.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T19:28:36.960+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:28:36.960+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T19:28:36.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.928 seconds
[2025-01-16T19:29:07.463+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:07.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:29:07.477+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:29:07.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:08.791+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:09.388+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-16T19:29:39.657+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:39.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T19:29:39.663+0000] {logging_mixin.py:190} INFO - [2025-01-16T19:29:39.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:40.410+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T19:29:41.666+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-16T20:05:45.217+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:05:45.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:05:45.226+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:45.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:05:46.863+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:05:47.052+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:47.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:05:47.073+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:05:47.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:05:47.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 1.909 seconds
[2025-01-16T20:06:17.678+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:17.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:06:17.682+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:17.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:18.216+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:18.231+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:18.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:06:18.240+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:18.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:06:18.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.592 seconds
[2025-01-16T20:06:49.051+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:49.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:06:49.053+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:49.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:49.564+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:06:49.576+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:49.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:06:49.585+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:06:49.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:06:49.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.553 seconds
[2025-01-16T20:07:19.765+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:19.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:07:19.768+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:19.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:20.293+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:20.310+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:20.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:07:20.319+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:20.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:07:20.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.583 seconds
[2025-01-16T20:07:50.900+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:50.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:07:50.903+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:50.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:51.378+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:07:51.392+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:51.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:07:51.400+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:07:51.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:07:51.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.536 seconds
[2025-01-16T20:08:21.661+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:21.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:08:21.664+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:21.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:22.199+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:22.215+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:22.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:08:22.226+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:22.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:08:22.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.586 seconds
[2025-01-16T20:08:52.467+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:52.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:08:52.471+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:52.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:53.097+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:08:53.116+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:53.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:08:53.128+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:08:53.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:08:53.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.695 seconds
[2025-01-16T20:09:23.966+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:23.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:09:23.969+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:23.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:24.441+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:24.460+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:24.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:09:24.471+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:24.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:09:24.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.544 seconds
[2025-01-16T20:09:54.728+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:54.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:09:54.731+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:54.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:55.189+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:09:55.212+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:55.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:09:55.227+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:09:55.227+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:09:55.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.528 seconds
[2025-01-16T20:10:25.439+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:25.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:10:25.442+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:25.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:25.792+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:25.807+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:25.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:10:25.815+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:25.815+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:10:25.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.408 seconds
[2025-01-16T20:10:56.230+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:56.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:10:56.233+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:56.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:56.626+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:10:56.643+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:56.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:10:56.653+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:10:56.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:10:56.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.460 seconds
[2025-01-16T20:11:27.314+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:27.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:11:27.317+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:27.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:27.715+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:27.731+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:27.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:11:27.742+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:27.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:11:27.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.459 seconds
[2025-01-16T20:11:58.561+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:58.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:11:58.564+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:58.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:58.941+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:11:58.957+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:58.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:11:58.967+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:11:58.967+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:11:58.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.427 seconds
[2025-01-16T20:12:29.242+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:12:29.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:12:29.245+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:29.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:12:29.613+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:12:29.629+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:29.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:12:29.639+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:29.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:12:29.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.431 seconds
[2025-01-16T20:12:59.898+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:12:59.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:12:59.901+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:12:59.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:13:00.327+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:13:00.343+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:00.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:13:00.352+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:00.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:13:00.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.477 seconds
[2025-01-16T20:13:31.015+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:13:31.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:13:31.018+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:31.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:13:31.375+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:13:31.390+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:31.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:13:31.400+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:13:31.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:13:31.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.422 seconds
[2025-01-16T20:14:01.753+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:01.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:14:01.756+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:01.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:02.165+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:02.184+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:02.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:14:02.197+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:02.197+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:14:02.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.467 seconds
[2025-01-16T20:14:32.518+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:32.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:14:32.521+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:32.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:32.943+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:14:32.958+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:32.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:14:32.967+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:14:32.967+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:14:32.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.482 seconds
[2025-01-16T20:15:03.421+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:03.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:15:03.424+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:03.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:03.795+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:03.811+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:03.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:15:03.822+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:03.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:15:03.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.436 seconds
[2025-01-16T20:15:34.058+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:34.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:15:34.061+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:34.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:34.497+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:15:34.518+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:34.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:15:34.527+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:15:34.527+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:15:34.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.493 seconds
[2025-01-16T20:16:05.224+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:05.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:16:05.227+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:05.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:05.594+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:05.610+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:05.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:16:05.619+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:05.619+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:16:05.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.416 seconds
[2025-01-16T20:16:36.143+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:36.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:16:36.146+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:36.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:36.596+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:16:36.613+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:36.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:16:36.627+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:16:36.626+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:16:36.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.515 seconds
[2025-01-16T20:17:07.649+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:07.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:17:07.651+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:07.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:08.014+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:08.030+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:08.029+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:17:08.041+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:08.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:17:08.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.428 seconds
[2025-01-16T20:17:38.206+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:38.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:17:38.209+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:38.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:38.562+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:17:38.577+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:38.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:17:38.586+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:17:38.586+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:17:38.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.399 seconds
[2025-01-16T20:18:08.912+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:08.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:18:08.914+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:08.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:09.377+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:09.400+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:09.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:18:09.411+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:09.411+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:18:09.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.524 seconds
[2025-01-16T20:18:40.463+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:40.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:18:40.466+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:40.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:40.892+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:18:40.910+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:40.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:18:40.920+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:18:40.920+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:18:40.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.485 seconds
[2025-01-16T20:19:11.742+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:11.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:19:11.747+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:11.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:12.308+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:12.334+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:12.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:19:12.348+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:12.348+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:19:12.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.652 seconds
[2025-01-16T20:19:43.127+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:43.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:19:43.131+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:43.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:43.646+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:19:43.670+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:43.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:19:43.682+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:19:43.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:19:43.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.582 seconds
[2025-01-16T20:20:14.381+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:14.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:20:14.385+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:14.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:14.845+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:14.865+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:14.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:20:14.877+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:14.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:20:14.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.552 seconds
[2025-01-16T20:20:45.744+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:45.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:20:45.747+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:45.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:46.227+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:20:46.250+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:46.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:20:46.261+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:20:46.261+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:20:46.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.560 seconds
[2025-01-16T20:21:16.392+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:16.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:21:16.396+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:16.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:16.921+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:16.950+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:16.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:21:16.965+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:16.965+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:21:16.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.602 seconds
[2025-01-16T20:21:47.655+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:47.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:21:47.659+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:47.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:48.252+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:21:48.280+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:48.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:21:48.297+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:21:48.297+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:21:48.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.688 seconds
[2025-01-16T20:22:18.547+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:18.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:22:18.550+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:18.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:19.070+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:19.096+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:19.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:22:19.118+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:19.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:22:19.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.617 seconds
[2025-01-16T20:22:49.302+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:49.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:22:49.306+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:49.305+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:49.816+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:22:49.839+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:49.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:22:49.855+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:22:49.855+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:22:49.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.597 seconds
[2025-01-16T20:23:20.734+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:20.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:23:20.739+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:20.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:21.252+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:21.278+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:21.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:23:21.290+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:21.290+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:23:21.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.588 seconds
[2025-01-16T20:23:52.009+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:52.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:23:52.012+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:52.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:52.484+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:23:52.505+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:52.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:23:52.517+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:23:52.517+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:23:52.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.532 seconds
[2025-01-16T20:24:23.334+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:23.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:24:23.337+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:23.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:23.728+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:23.744+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:23.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:24:23.753+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:23.753+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:24:23.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.444 seconds
[2025-01-16T20:24:54.625+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:54.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:24:54.628+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:54.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:55.044+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:24:55.060+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:55.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:24:55.070+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:24:55.070+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:24:55.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.467 seconds
[2025-01-16T20:25:25.673+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:25.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:25:25.676+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:25.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:26.070+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:26.086+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:26.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:25:26.096+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:26.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:25:26.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.454 seconds
[2025-01-16T20:25:56.584+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:56.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:25:56.588+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:56.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:57.035+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:25:57.052+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:57.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:25:57.062+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:25:57.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:25:57.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.504 seconds
[2025-01-16T20:26:27.643+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:26:27.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_clickhouse_test.py for tasks to queue
[2025-01-16T20:26:27.645+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:27.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:26:28.005+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_test' retrieved from /opt/airflow/dags/spark_clickhouse_test.py
[2025-01-16T20:26:28.022+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:28.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-16T20:26:28.032+0000] {logging_mixin.py:190} INFO - [2025-01-16T20:26:28.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_test to None, run_after=None
[2025-01-16T20:26:28.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_clickhouse_test.py took 0.423 seconds
